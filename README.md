# merchant-identifier
Quick example of NER to identify merchants from financial transaction data

My goal with this project is to show some good basic ML training principles and keep it under 3 hours (Update: I ended up taking ~4hrs). This project was based on spaCy's ner_demo project template, which I chose because it runs fine locally and has nice support for workflows, keeping track of the model configuration, and shipping the model.


## What's in here?
- This project was based on the [ner_demo project template](https://github.com/explosion/projects/tree/v3/pipelines/ner_dem). Weasel creates a workflow from the [`ner_demo/project.yml`](ner_demo/project.yml) file, with upstream "deps" and downstream "outputs". See the auto-generated documentation of my workflow in the [`ner_demo readme`](ner_demo/README.md). Running a workflow generates a `project.lock` file with hash functions to check if any dependencies have changed, and if they haven't, the step will be skipped so you're not re-running the same thing multiple times. Convenient!
- The [`ner_demo/configs/config.cfg`](ner_demo/configs/config.cfg) specifies the config of the model, itself, as well as how the model was trained (hyperparameters, optimizer, etc.). This makes model training a lot more reproducible. Some of the model config, like the version number and some performance stats,  is also kept with the final packaged model in the metadata so it's easy to find. This model's pipeline is a tokenizer, an "entity ruler" that applies pattern matching, and finally a named entity recognition model.
- The labeled data was bootstrapped with the `ner_demo/scripts/bootstrap.ipynb` notebook. I'd add some patterns for the model to automatically recognize as a named entity, then use the model to label named entities, and using the outputs that the model got right as my labeled data. Then I incrementally add more patterns, have more labeled data, retrain again with the new labeled data, rinse, repeat. This was the most time consuming part, though I could see the model getting more accurate as I built up the training dataset. 
- The base model is spaCy's most lightweight model, just for starting off. Ultimately it could be swapped out for any model on [the HuggingFace Hub](https://huggingface.co/models).
- The end result is a python packaged model. I've included just the compressed tarball in `ner_demo/packages/en_ner_demo-0.0.0/dist/en_ner_demo-0.0.0.tar.gz`. It's ready to go into any docker container, easy to version, can be deployed with [spaCy's fastAPI integration](https://spacy.io/usage/projects#fastapi).


## Limitations:
- I would’ve liked to use a model that can also use the other fields beyond just the description, but I suspect some of those are generated by other ML models and it might be a trash-in-trash-out situation, so I’m not too pressed about it.
- Could've used some of the "cleaner" descriptions to auto-label some observations. In the past I've seen that some financial sources just have the merchant name in the description. Descriptions from those sources can be used to quickly make a database of merchants.
- My base model has many other types of named entities, like locations and people, that are muddying up the results. I'd like to tailor them more to this use case.
- I don't love having pattern matching in the final product because it means maintaining a list of essentially regex keywords. spaCy does do a better job than regex since it works on tokens instead of raw text, making it faster and more accurate when words are truncated, but I'd still use the pattern matching "entity ruler" component just for the initial prototyping.
- Pretraining ended up taking forever, I let it run overnight on a dataset of 100k observations. Didn't do anything fancy like using GPU. At least I only had to run it once!
- 

